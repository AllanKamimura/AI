{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "buzzleixo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCBdsq3M6n5zq8CSSjNmp5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllanKamimura/AI/blob/master/buzzleixo/buzzleixo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB7nMD622mbm"
      },
      "source": [
        "### Inicializador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KplhAvBh2rre"
      },
      "source": [
        "#importa as bibliotecas ai\r\n",
        "import os\r\n",
        "import zipfile\r\n",
        "import datetime\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "from tf.keras.preprocessing import image\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MvZhWZpvkWF"
      },
      "source": [
        "#baixa os arquivos do dataset\n",
        "!wget --no-check-certificate \\\n",
        "    https://github.com/AllanKamimura/AI/blob/master/buzzleixo/train.zip?raw=true \\\n",
        "    -O /tmp/Train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcZmojWW2ulu"
      },
      "source": [
        "### Estrutura dos dados\r\n",
        "```\r\n",
        "── Train\r\n",
        "    ├── Buzz\r\n",
        "    │   ├── Buzz1.jpg\r\n",
        "    │   ├── Buzz2.jpg\r\n",
        "    │   └──  ...\r\n",
        "    └── Juju\r\n",
        "        ├── Juju1.jpg\r\n",
        "        ├── Juju2.jpg\r\n",
        "        └──  ...\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-otxdfs_J5Uy"
      },
      "source": [
        "local_zip = '/tmp/Train.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Directory with our training buzz pictures\n",
        "train_buzz_dir = os.path.join('/tmp/Train/Buzz')\n",
        "\n",
        "# Directory with our training juju pictures\n",
        "train_juju_dir = os.path.join('/tmp/Train/Juju')\n",
        "\n",
        "train_buzz_names = os.listdir(train_buzz_dir)\n",
        "print(train_buzz_names[:10])\n",
        "\n",
        "train_juju_names = os.listdir(train_juju_dir)\n",
        "print(train_juju_names[:10])\n",
        "\n",
        "print('total training buzz images:', len(os.listdir(train_buzz_dir)))\n",
        "print('total training juju images:', len(os.listdir(train_juju_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS7t45J6NuTJ"
      },
      "source": [
        "# All images will be rescaled by 1./255 + data augmentation\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        "    rotation_range = 45,\n",
        "    width_shift_range = 0.4,\n",
        "    height_shift_range = 0.4,\n",
        "    shear_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    zoom_range = 0.5,\n",
        "    fill_mode = 'nearest')\n",
        "\n",
        "\n",
        "# Flow training images in batches  using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/tmp/train',  # This is the source directory for training images\n",
        "        target_size=(300, 300),  # All images will be resized to 300x300\n",
        "        batch_size= 10,\n",
        "        shuffle = True,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn_DVboz2-tC"
      },
      "source": [
        "### Rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AZ3IrKCOqMN"
      },
      "source": [
        "nodes = 32 \n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D( nodes , (3,3), activation = \"relu\", input_shape = (300,300,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D( 2*nodes, (3,3), activation = \"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D( 4*nodes, (3,3), activation = \"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D( 8*nodes, (3,3), activation = \"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense( 10*nodes, activation = \"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation = \"sigmoid\")])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcV2uSF6Oz9W"
      },
      "source": [
        "model.compile(\n",
        "    loss = \"binary_crossentropy\", \n",
        "    optimizer = \"RMSprop\", \n",
        "    metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxQJJAZxPAl7"
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 10,\n",
        "    batch_size = 10,\n",
        "    epochs = 25,\n",
        "    verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuPEauVg3CCP"
      },
      "source": [
        "### Faça o upload da imagem e veja o resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ex1TWN6PK7k"
      },
      "source": [
        "uploaded = files.upload() #botão de fazer upload\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn #salva as imagens uploudadas aqui\n",
        "  img = image.load_img(path, target_size=(300, 300)) #usa o keras.preprocess para abrir a imagem\n",
        "  x = image.img_to_array(img) # transforma a imagem em um array\n",
        "  x = np.expand_dims(x, axis=0) #aumenta as dimensões do array (batch_size, altura, largura, canal)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size = 10)\n",
        "  print(classes[0])\n",
        "  if classes[0] > 0.5:\n",
        "    print(fn + \" É UM ABACATE\")\n",
        "    %pylab inline\n",
        "    img = image.load_img('/tmp/aleixo.jpg')\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "  else:\n",
        "    print(fn + \" É UM BUZZLATIR\")\n",
        "    %pylab inline\n",
        "    img = image.load_img('/tmp/buzz.jpg')\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPCScNlK3Es1"
      },
      "source": [
        "### Salve seus pesos\r\n",
        "obs os arquivos temporarios (/tmp/) serão deletados quando a sessão for encerrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTe5xnpaah1W"
      },
      "source": [
        "#cria um savepoint com a hora num fuso horario estranho ai\r\n",
        "def save():\r\n",
        "    now = datetime.datetime.now() \r\n",
        "    now = \"{}_{}_{}_{}_{}\".format(now.year,now.month,now.day,now.hour,now.minute)\r\n",
        "    model.save(\"/tmp/\" + now + \".h5\")\r\n",
        "save()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}