{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification Pokemon v1",
      "provenance": [],
      "authorship_tag": "ABX9TyPyyVzgse27F+I2B1NpvO1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllanKamimura/AI/blob/master/IEEE/Classification_Pokemon_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9x2TqlIupfp"
      },
      "source": [
        "#Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZMZFIhNuW6r"
      },
      "source": [
        "# import libraries\n",
        "import os\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "from google_drive_downloader import GoogleDriveDownloader\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAw7b9qJueUw"
      },
      "source": [
        "file_id = \"1lKfmEjyovEvvZ2zBUkdJwl2fnF4C5OyM\" # pokemon dataset id\n",
        "folder = \"dataset\" # main folder\n",
        "\n",
        "# download data\n",
        "GoogleDriveDownloader.download_file_from_google_drive(\n",
        "    file_id = file_id,\n",
        "    dest_path = \"/content/pokemon.zip\",\n",
        "    unzip = True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YDFuUpyuiej"
      },
      "source": [
        "# explore data\n",
        "pokemon_count = {}\n",
        "index_weight = {} # class imbalance => class_weight = total_images / class_samples\n",
        "pokemon_list = os.listdir(\"/content/{}\".format(folder))\n",
        "pokemon_list.sort() # alphabetical order\n",
        "\n",
        "for index, pokemon in enumerate(pokemon_list):\n",
        "    pokemon_count[pokemon] = len(os.listdir(\"/content/{}/{}\".format(folder, pokemon)))\n",
        "    index_weight[index] = 1 / len(os.listdir(\"/content/{}/{}\".format(folder, pokemon)))\n",
        "\n",
        "index_weight = {k: v * total for total in (sum(index_weight.values()),) for k, v in index_weight.items()}\n",
        "\n",
        "fig = plt.figure(figsize = (25, 5))\n",
        "sns.lineplot(x = list(pokemon_count.keys()), y = list(pokemon_count.values())).set_title('Number of images for each pokemon')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.margins(x=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4naat67cve0I"
      },
      "source": [
        "# Create data feed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7TETao9vk0a"
      },
      "source": [
        "seed = 2\n",
        "height, width = 224, 224\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split = 0.1)\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    directory = \"/content/{}\".format(folder),\n",
        "    target_size = (height, width),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    batch_size = 20,\n",
        "    subset = \"training\"\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    directory = \"/content/{}\".format(folder),\n",
        "    target_size = (height, width),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    batch_size = 20,\n",
        "    subset = \"validation\"\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    validation_split = 0.1\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    directory = \"/content/{}\".format(folder),\n",
        "    target_size = (height, width),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    batch_size = 20,\n",
        "    subset = \"validation\"\n",
        ")\n",
        "\n",
        "# get the inverse of class_indices\n",
        "indices_class = {value: key for key, value in val_data.class_indices.items()}\n",
        "print(indices_class)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hz4TPtFv1qR"
      },
      "source": [
        "# Efficient + Xception + mobile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KX54zihv8G3"
      },
      "source": [
        "def base_model(shape):\n",
        "    \"\"\"\n",
        "    base_model as a function, create the convolutional layers\n",
        "    Parameters:\n",
        "    shape = the shape of the input, tuple (height, width, channels)\n",
        "    Returns:\n",
        "    a tensorflow model object\n",
        "    \"\"\"\n",
        "    # make an input layer, with shape equals to the input_shape\n",
        "    input = tf.keras.layers.Input(shape = shape, name = \"input_layer\")\n",
        "    \n",
        "    # preprocess the input\n",
        "    efficient_input = tf.keras.applications.efficientnet.preprocess_input(input)\n",
        "    xception_input = tf.keras.applications.xception.preprocess_input(input)\n",
        "    mobile_input = tf.keras.applications.mobilenet_v3.preprocess_input(input)\n",
        "\n",
        "    # instantiate the pre-trained model\n",
        "    efficient_model = tf.keras.applications.EfficientNetB7(include_top = False, # don't include the Fully Conected Layers\n",
        "                                                           input_shape = input_shape, \n",
        "                                                           pooling = \"max\", # returns a flatten layer\n",
        "                                                           weights = \"imagenet\") \n",
        "    \n",
        "    xception_model = tf.keras.applications.Xception(include_top = False,\n",
        "                                                    input_shape = input_shape,\n",
        "                                                    pooling = \"max\",\n",
        "                                                    weights = \"imagenet\")\n",
        "    \n",
        "    mobile_model = tf.keras.applications.MobileNetV3Small(include_top = False,\n",
        "                                                          input_shape = input_shape,\n",
        "                                                          pooling = \"max\",\n",
        "                                                          minimalistic = True,\n",
        "                                                          weights = \"imagenet\")\n",
        "    \n",
        "    efficient_model.trainable = False # freeze model weights training\n",
        "    xception_model.trainable = False\n",
        "    mobile_model.trainable = False\n",
        "\n",
        "    efficient_output = efficient_model(efficient_input) # feed the each preprocessed image in the right pre-trained model\n",
        "    xception_output = xception_model(xception_input)\n",
        "    mobile_output = mobile_model(mobile_input)\n",
        "\n",
        "    y = tf.keras.layers.Concatenate()([efficient_output, # concatenate the 3 outputs into a single layer\n",
        "                                       xception_output,\n",
        "                                       mobile_output])\n",
        "    \n",
        "    model = tf.keras.models.Model( # instantiate the tensorflow model with input as the input and y as the output\n",
        "        inputs = input,\n",
        "        outputs = y)  \n",
        "    \n",
        "    return model\n",
        "\n",
        "def my_model(n_class):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(units = 4096, activation = \"relu\", kernel_initializer = 'he_uniform'),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(units = 1024, activation = \"relu\", kernel_initializer = 'he_uniform'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(units = 256, activation = \"relu\", kernel_initializer = 'he_uniform'),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(units = n_class, activation = \"softmax\")\n",
        "    ])\n",
        "    return model  \n",
        "\n",
        "input_shape = (height, width, 3)\n",
        "n_class = len(train_data.class_indices.keys())\n",
        "\n",
        "conv_model = base_model(shape = (height,width,3))\n",
        "fc_model = my_model(n_class = n_class)\n",
        "\n",
        "model = tf.keras.models.Sequential([conv_model, fc_model])\n",
        "\n",
        "model.summary()                              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT2KljhUyGjS"
      },
      "source": [
        "# train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "817Vp3a-yIQP"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        tf.keras.optimizers.schedules.ExponentialDecay( # after 6000 steps, the learning rate is updated to half the initial value\n",
        "            initial_learning_rate = 0.0004, decay_steps = 6000, decay_rate = 0.5 # this number is a hyperparameter, so adjust accordingly\n",
        "    )),\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjQtuKLRyI-z"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq = 1)\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 3, restore_best_weights = True)\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                    validation_data = val_data,\n",
        "                    epochs = 20,\n",
        "                    callbacks = [tensorboard_callback, callback],\n",
        "                    class_weight = index_weight # apply the class_weight\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBi_F8SUy6a2"
      },
      "source": [
        "%tensorboard --logdir logs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1C_DAbPy9bm"
      },
      "source": [
        "# Visualize predits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAVCmPnXzBRa"
      },
      "source": [
        "images, labels = test_data.next() # get the next batch of test data\n",
        "predicts = model.predict(images) # get the predictions\n",
        "\n",
        "n_rows = (len(images) // 4) + 1\n",
        "plt.figure(figsize = (12,n_rows * 4))\n",
        "\n",
        "for index, image in enumerate(images):\n",
        "    plt.subplot(n_rows, 4, index + 1)\n",
        "    image = np.asarray(image, dtype = np.uint8)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"real: {}\\n predict:{}\\n score:{:.3f}\".format(\n",
        "        indices_class[np.argmax(labels[index])], \n",
        "        indices_class[np.argmax(predicts[index])],\n",
        "        np.max(predicts[index])\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}