{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification Pokemon v1",
      "provenance": [],
      "authorship_tag": "ABX9TyNaQ3TK/glV2SXZrE5TqtMz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllanKamimura/AI/blob/master/IEEE/Classification_Pokemon_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9x2TqlIupfp"
      },
      "source": [
        "#Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZMZFIhNuW6r"
      },
      "source": [
        "# import libraries\n",
        "import os\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "from google_drive_downloader import GoogleDriveDownloader\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAw7b9qJueUw"
      },
      "source": [
        "file_id = \"1lKfmEjyovEvvZ2zBUkdJwl2fnF4C5OyM\" # pokemon dataset id\n",
        "folder = \"dataset\" # main folder\n",
        "\n",
        "# download data\n",
        "GoogleDriveDownloader.download_file_from_google_drive(\n",
        "    file_id = file_id,\n",
        "    dest_path = \"/content/pokemon.zip\",\n",
        "    unzip = True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YDFuUpyuiej"
      },
      "source": [
        "# explore data\n",
        "pokemon_count = {}\n",
        "index_weight = {} # class imbalance => class_weight = total_images / class_samples\n",
        "pokemon_list = os.listdir(\"/content/{}\".format(folder))\n",
        "pokemon_list.sort() # alphabetical order\n",
        "\n",
        "for index, pokemon in enumerate(pokemon_list):\n",
        "    pokemon_count[pokemon] = len(os.listdir(\"/content/{}/{}\".format(folder, pokemon)))\n",
        "    index_weight[index] = 1 / len(os.listdir(\"/content/{}/{}\".format(folder, pokemon)))\n",
        "\n",
        "index_weight = {k: v * total for total in (sum(index_weight.values()),) for k, v in index_weight.items()}\n",
        "\n",
        "fig = plt.figure(figsize = (25, 5))\n",
        "sns.lineplot(x = list(pokemon_count.keys()), y = list(pokemon_count.values())).set_title('Number of images for each pokemon')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.margins(x=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4naat67cve0I"
      },
      "source": [
        "# Create data feed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7TETao9vk0a"
      },
      "source": [
        "seed = 2\n",
        "height, width = 224, 224\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split = 0.1)\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    directory = \"/content/{}\".format(folder),\n",
        "    target_size = (height, width),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    batch_size = 20,\n",
        "    subset = \"training\"\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    directory = \"/content/{}\".format(folder),\n",
        "    target_size = (height, width),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    batch_size = 20,\n",
        "    subset = \"validation\"\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    validation_split = 0.1\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    directory = \"/content/{}\".format(folder),\n",
        "    target_size = (height, width),\n",
        "    shuffle = True,\n",
        "    seed = seed,\n",
        "    batch_size = 20,\n",
        "    subset = \"validation\"\n",
        ")\n",
        "\n",
        "# get the inverse of class_indices\n",
        "indices_class = {value: key for key, value in val_data.class_indices.items()}\n",
        "print(indices_class)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEWKUQo_2DGC"
      },
      "source": [
        "# Model Build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hz4TPtFv1qR"
      },
      "source": [
        "## Efficient + Xception + mobile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KX54zihv8G3"
      },
      "source": [
        "def base_model(shape):\n",
        "    \"\"\"\n",
        "    base_model as a function, create the convolutional layers\n",
        "    Parameters:\n",
        "    shape = the shape of the input, tuple (height, width, channels)\n",
        "    Returns:\n",
        "    a tensorflow model object\n",
        "    \"\"\"\n",
        "    # make an input layer, with shape equals to the input_shape\n",
        "    input = tf.keras.layers.Input(shape = shape, name = \"input_layer\")\n",
        "    \n",
        "    # preprocess the input\n",
        "    efficient_input = tf.keras.applications.efficientnet.preprocess_input(input)\n",
        "    xception_input = tf.keras.applications.xception.preprocess_input(input)\n",
        "    mobile_input = tf.keras.applications.mobilenet_v3.preprocess_input(input)\n",
        "\n",
        "    # instantiate the pre-trained model\n",
        "    efficient_model = tf.keras.applications.EfficientNetB7(include_top = False, # don't include the Fully Conected Layers\n",
        "                                                           input_shape = input_shape, \n",
        "                                                           pooling = \"max\", # returns a flatten layer\n",
        "                                                           weights = \"imagenet\") \n",
        "    \n",
        "    xception_model = tf.keras.applications.Xception(include_top = False,\n",
        "                                                    input_shape = input_shape,\n",
        "                                                    pooling = \"max\",\n",
        "                                                    weights = \"imagenet\")\n",
        "    \n",
        "    mobile_model = tf.keras.applications.MobileNetV3Small(include_top = False,\n",
        "                                                          input_shape = input_shape,\n",
        "                                                          pooling = \"max\",\n",
        "                                                          minimalistic = True,\n",
        "                                                          weights = \"imagenet\")\n",
        "    \n",
        "    efficient_model.trainable = False # freeze model weights training\n",
        "    xception_model.trainable = False\n",
        "    mobile_model.trainable = False\n",
        "\n",
        "    efficient_output = efficient_model(efficient_input) # feed the each preprocessed image in the right pre-trained model\n",
        "    xception_output = xception_model(xception_input)\n",
        "    mobile_output = mobile_model(mobile_input)\n",
        "\n",
        "    y = tf.keras.layers.Concatenate()([efficient_output, # concatenate the 3 outputs into a single layer\n",
        "                                       xception_output,\n",
        "                                       mobile_output])\n",
        "    \n",
        "    model = tf.keras.models.Model( # instantiate the tensorflow model with input as the input and y as the output\n",
        "        inputs = input,\n",
        "        outputs = y)  \n",
        "    \n",
        "    return model\n",
        "\n",
        "def my_model(n_class):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(units = 4096, activation = \"relu\", kernel_initializer = 'he_uniform'),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(units = 1024, activation = \"relu\", kernel_initializer = 'he_uniform'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(units = 256, activation = \"relu\", kernel_initializer = 'he_uniform'),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(units = n_class, activation = \"softmax\")\n",
        "    ])\n",
        "    return model  \n",
        "\n",
        "input_shape = (height, width, 3)\n",
        "n_class = len(train_data.class_indices.keys())\n",
        "\n",
        "conv_model = base_model(shape = (height,width,3))\n",
        "fc_model = my_model(n_class = n_class)\n",
        "\n",
        "model = tf.keras.models.Sequential([conv_model, fc_model])\n",
        "\n",
        "model.summary()                              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4gmf1zd32Wi"
      },
      "source": [
        "## vgg + resnet + xception model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKzm8zGO7ccG"
      },
      "source": [
        "### VGG-19 (2014)\n",
        "[paper](https://arxiv.org/abs/1409.1556)\n",
        "\n",
        "[TensorFlow implementation](https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/applications/vgg19.py#L45-L231)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxgeuUix4V0x"
      },
      "source": [
        "def block(x, n_convs, filters, block_name, kernel_size = (3, 3), activation = \"relu\", pool_size = (2, 2), pool_stride = (2, 2)):\n",
        "  '''\n",
        "  Defines a block in the VGG network.\n",
        "\n",
        "  Returns:\n",
        "    tensor containing the max-pooled output of the convolutions\n",
        "  '''\n",
        "\n",
        "  for i in range(n_convs):\n",
        "      x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding = \"same\", name=\"{}_conv{}\".format(block_name, i + 1),\n",
        "                                 kernel_initializer = \"he_uniform\")(x)\n",
        "    \n",
        "  x = tf.keras.layers.MaxPooling2D(pool_size = pool_size, strides = pool_stride, name = \"{}_pool{}\".format(block_name, i+1))(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def VGG_19(shape, n_class, pool):\n",
        "    input = tf.keras.layers.Input(shape = shape, name = \"input_layer\")\n",
        "    x = input\n",
        "\n",
        "    x = block(x, n_convs = 2, filters = 64, block_name = \"block1\")\n",
        "    x = block(x, n_convs = 2, filters = 128, block_name = \"block2\")\n",
        "    x = block(x, n_convs = 4, filters = 256, block_name = \"block3\")\n",
        "    x = block(x, n_convs = 4, filters = 512, block_name = \"block4\")\n",
        "    x = block(x, n_convs = 4, filters = 512, block_name = \"block5\")\n",
        "\n",
        "    if pool == \"average\":\n",
        "        y = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    if pool == \"max\":\n",
        "        y = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # y = tf.keras.layers.Dense(units = n_class, activation = \"softmax\", kernel_initializer = \"he_uniform\")(y)\n",
        "\n",
        "    model = tf.keras.Model(\n",
        "        inputs = input,\n",
        "        outputs = y,\n",
        "        name = \"vgg19_model\"\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iooxYbSN6-_-"
      },
      "source": [
        "### ResNet-50 (2015)\n",
        "[paper](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "[TensorFlow implementation](https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/applications/resnet.py#L453-L472)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU5q0M7T4ea3"
      },
      "source": [
        "def res_conv(x, filters, activation = \"relu\", epsilon = 1.001e-5, strides = (1, 1)):\n",
        "    x_short = tf.keras.layers.Conv2D(filters = 4 * filters, kernel_size = (1, 1), kernel_initializer = \"he_uniform\",\n",
        "                                     strides = strides)(x)\n",
        "    x_short = tf.keras.layers.BatchNormalization(epsilon = epsilon)(x_short)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters = filters, kernel_size = (1, 1), kernel_initializer = \"he_uniform\",\n",
        "                               strides = strides)(x)\n",
        "    x = tf.keras.layers.BatchNormalization(epsilon = epsilon)(x)\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), padding = \"same\", kernel_initializer = \"he_uniform\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(epsilon = epsilon)(x)\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters = 4 * filters, kernel_size = (1, 1), kernel_initializer = \"he_uniform\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(epsilon = epsilon)(x)\n",
        "\n",
        "    x = tf.keras.layers.Add()([x, x_short])\n",
        "    y = tf.keras.layers.Activation(activation = activation)(x)\n",
        "    return y\n",
        "\n",
        "def res_id(x, filters, activation = \"relu\", epsilon = 1.001e-5):\n",
        "    x_short = x\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters = filters, kernel_size = (1, 1), kernel_initializer = \"he_uniform\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(epsilon = epsilon)(x)\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters = filters, kernel_size = (3, 3), padding = \"same\", kernel_initializer = \"he_uniform\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(epsilon = epsilon)(x)\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters = 4 * filters, kernel_size = (1, 1), kernel_initializer = \"he_uniform\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization(epsilon = epsilon)(x)\n",
        "\n",
        "    x = tf.keras.layers.Add()([x, x_short])\n",
        "    y = tf.keras.layers.Activation(activation = activation)(x)\n",
        "    return y\n",
        "\n",
        "def resnet_50(shape, n_class, pool):\n",
        "    input = tf.keras.layers.Input(shape = shape, name = \"input_layer\")\n",
        "\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=((3, 3)))(input)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (7, 7), kernel_initializer = \"he_uniform\",\n",
        "                               strides = (2, 2))(x)\n",
        "    x = tf.keras.layers.BatchNormalization(epsilon = 1.001e-5)(x)\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(3, strides = 2)(x)\n",
        "\n",
        "    x = res_conv(x = x, filters = 64)\n",
        "    x = res_id(x = x, filters = 64)\n",
        "    x = res_id(x = x, filters = 64)\n",
        "\n",
        "    x = res_conv(x = x, filters = 128, strides = (2, 2))\n",
        "    x = res_id(x = x, filters = 128)\n",
        "    x = res_id(x = x, filters = 128)\n",
        "    x = res_id(x = x, filters = 128)\n",
        "\n",
        "    x = res_conv(x = x, filters = 256, strides = (2, 2))\n",
        "    x = res_id(x = x, filters = 256)\n",
        "    x = res_id(x = x, filters = 256)\n",
        "    x = res_id(x = x, filters = 256)\n",
        "    x = res_id(x = x, filters = 256)\n",
        "    x = res_id(x = x, filters = 256)\n",
        "\n",
        "    x = res_conv(x = x, filters = 512, strides = (2, 2))\n",
        "    x = res_id(x = x, filters = 512)\n",
        "    x = res_id(x = x, filters = 512)\n",
        "\n",
        "    if pool == \"average\":\n",
        "        y = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    if pool == \"max\":\n",
        "        y = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # y = tf.keras.layers.Dense(units = n_class, activation = \"softmax\", kernel_initializer = \"he_uniform\")(y)\n",
        "\n",
        "    model = tf.keras.Model(\n",
        "        inputs = input,\n",
        "        outputs = y,\n",
        "        name = \"resnet_model\"\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9u8S9sO728n"
      },
      "source": [
        "### Xception (2016)\n",
        "[paper](https://arxiv.org/abs/1610.02357)\n",
        "\n",
        "[TensorFlow implementation](https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/python/keras/applications/xception.py#L50-L315)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57dIpgsa8Fsu"
      },
      "source": [
        "def xception_convA(x, filters, activation = \"relu\"):\n",
        "    x_short = tf.keras.layers.Conv2D(filters = filters, kernel_size = (1, 1), strides = (2, 2), kernel_initializer = \"he_uniform\",\n",
        "                                     padding = \"same\", use_bias = False)(x)\n",
        "    x_short = tf.keras.layers.BatchNormalization()(x_short)\n",
        "\n",
        "    x = tf.keras.layers.SeparableConv2D(filters = filters, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                                        padding = \"same\", use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "\n",
        "    x = tf.keras.layers.SeparableConv2D(filters = filters, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                                        padding = \"same\", use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x) \n",
        "\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size = (3, 3), strides = (2, 2),\n",
        "                                     padding = \"same\")(x)\n",
        "    y = tf.keras.layers.Add()([x, x_short])  \n",
        "\n",
        "    return y\n",
        "\n",
        "def xception_convB(x, filters, activation = \"relu\"):\n",
        "    x_short = x\n",
        "\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(filters = filters, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                                        padding = \"same\", use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(filters = filters, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                                        padding = \"same\", use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(filters = filters, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                                        padding = \"same\", use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    y = tf.keras.layers.Add()([x, x_short])\n",
        "\n",
        "    return y\n",
        "\n",
        "def xception_convC(x, filters, activation = \"relu\"):\n",
        "    x_short = tf.keras.layers.Conv2D(filters = filters, kernel_size = (1, 1), strides = (2, 2), kernel_initializer = \"he_uniform\",\n",
        "                                     padding = \"same\", use_bias = False)(x)\n",
        "    x_short = tf.keras.layers.BatchNormalization()(x_short)\n",
        "\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(filters = 728, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                                        padding = \"same\", use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = tf.keras.layers.Activation(activation = activation)(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(filters = filters, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                                        padding = \"same\", use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size = (3, 3), strides = (2, 2),\n",
        "                                     padding = \"same\")(x)\n",
        "    y = tf.keras.layers.Add()([x, x_short])  \n",
        "\n",
        "    return y\n",
        "\n",
        "def xception(shape, n_class, pool):\n",
        "    input = tf.keras.layers.Input(shape = shape)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), strides = (2, 2), kernel_initializer = \"he_uniform\",\n",
        "                               use_bias = False)(input)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(activation = \"relu\")(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                               use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(activation = \"relu\")(x)\n",
        "    \n",
        "    x = xception_convA(x = x, filters = 128)\n",
        "    x = xception_convA(x = x, filters = 256)\n",
        "    x = xception_convA(x = x, filters = 728)\n",
        "\n",
        "    x = xception_convB(x = x, filters = 728)\n",
        "    x = xception_convB(x = x, filters = 728)\n",
        "    x = xception_convB(x = x, filters = 728)\n",
        "    x = xception_convB(x = x, filters = 728)\n",
        "    x = xception_convB(x = x, filters = 728)\n",
        "    x = xception_convB(x = x, filters = 728)\n",
        "    x = xception_convB(x = x, filters = 728)\n",
        "    x = xception_convB(x = x, filters = 728)\n",
        "\n",
        "    x = xception_convC(x = x, filters = 1024)\n",
        "\n",
        "    x = tf.keras.layers.SeparableConv2D(filters = 1536, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                                        padding = \"same\", use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(activation = \"relu\")(x)\n",
        "\n",
        "    x = tf.keras.layers.SeparableConv2D(filters = 2048, kernel_size = (3, 3), kernel_initializer = \"he_uniform\",\n",
        "                                        padding = \"same\", use_bias = False)(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(activation = \"relu\")(x)\n",
        "\n",
        "    if pool == \"average\":\n",
        "        y = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    if pool == \"max\":\n",
        "        y = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # y = tf.keras.layers.Dense(units = n_class, activation = \"softmax\", kernel_initializer = \"he_uniform\")(y)\n",
        "\n",
        "    model = tf.keras.Model(\n",
        "        inputs = input,\n",
        "        outputs = y,\n",
        "        name = \"xception_model\"\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7k202WQBUDu"
      },
      "source": [
        "### my_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5xAvqUPBZhU"
      },
      "source": [
        "def normalizaion(shape):\n",
        "    mean = np.array([127.5] * 3)\n",
        "    input = tf.keras.layers.Input(shape = shape, name = \"input_layer\")\n",
        "    y = tf.keras.layers.experimental.preprocessing.Normalization(\n",
        "        mean = mean,\n",
        "        variance = mean ** 2)(input)\n",
        "\n",
        "    model = tf.keras.Model(\n",
        "            inputs = input,\n",
        "            outputs = y,\n",
        "            name = \"normalization_layer\"\n",
        "        )\n",
        "    \n",
        "    return model\n",
        "\n",
        "def my_model(shape):\n",
        "    input = tf.keras.layers.Input(shape)\n",
        "\n",
        "    vgg_model = VGG_19(shape = (height,width,3), n_class = n_class, pool = \"max\")\n",
        "    resnet_model = resnet_50(shape = (height,width,3), n_class = n_class, pool = \"max\")\n",
        "    xception_model = xception(shape = (height,width,3), n_class = n_class, pool = \"max\")\n",
        "\n",
        "    vgg_out = vgg_model(input)\n",
        "    resnet_out = resnet_model(input)\n",
        "    xception_out = xception_model(input)\n",
        "\n",
        "    y = tf.keras.layers.Concatenate(name = \"junta_tudo\")([vgg_out,\n",
        "                                                          resnet_out, \n",
        "                                                          xception_out])\n",
        "    model = tf.keras.Model(\n",
        "        inputs = input,\n",
        "        outputs = y,\n",
        "        name = \"conv_model\"\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def fc_model(n_class):\n",
        "    model = tf.keras.Sequential([\n",
        "                                 tf.keras.layers.Dropout(0.5),\n",
        "                                 tf.keras.layers.LayerNormalization(),\n",
        "                                 tf.keras.layers.Dense(units = 2048, activation = \"relu\"),\n",
        "                                 tf.keras.layers.Dropout(0.5),\n",
        "                                 tf.keras.layers.LayerNormalization(),\n",
        "                                 tf.keras.layers.Dense(units = 512, activation = \"relu\"),\n",
        "                                 tf.keras.layers.Dropout(0.5),\n",
        "                                 tf.keras.layers.LayerNormalization(),\n",
        "                                 tf.keras.layers.Dense(n_class, activation = \"softmax\")\n",
        "    ], name = \"fc_model\")\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvY5gsCrBi5d"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "conv_model = my_model(shape = (height,width,3))\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             normalizaion(shape = (height,width,3)),\n",
        "                             conv_model,\n",
        "                             fc_model(n_class = n_class)\n",
        "], name = \"my_model\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwgYAo96Bu9G"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes = True, expand_nested = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT2KljhUyGjS"
      },
      "source": [
        "# train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "817Vp3a-yIQP"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        tf.keras.optimizers.schedules.ExponentialDecay( # after 6000 steps, the learning rate is updated to half the initial value\n",
        "            initial_learning_rate = 0.0004, decay_steps = 6000, decay_rate = 0.5 # this number is a hyperparameter, so adjust accordingly\n",
        "    )),\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjQtuKLRyI-z"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq = 1)\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 3, restore_best_weights = True)\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                    validation_data = val_data,\n",
        "                    epochs = 20,\n",
        "                    callbacks = [tensorboard_callback, callback],\n",
        "                    class_weight = index_weight # apply the class_weight\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBi_F8SUy6a2"
      },
      "source": [
        "%tensorboard --logdir logs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1C_DAbPy9bm"
      },
      "source": [
        "# Visualize predits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAVCmPnXzBRa"
      },
      "source": [
        "images, labels = test_data.next() # get the next batch of test data\n",
        "predicts = model.predict(images) # get the predictions\n",
        "\n",
        "n_rows = (len(images) // 4) + 1\n",
        "plt.figure(figsize = (12,n_rows * 4))\n",
        "\n",
        "for index, image in enumerate(images):\n",
        "    plt.subplot(n_rows, 4, index + 1)\n",
        "    image = np.asarray(image, dtype = np.uint8)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"real: {}\\n predict:{}\\n score:{:.3f}\".format(\n",
        "        indices_class[np.argmax(labels[index])], \n",
        "        indices_class[np.argmax(predicts[index])],\n",
        "        np.max(predicts[index])\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}